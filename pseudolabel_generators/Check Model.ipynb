{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, re, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# GCS_PATH_ORI = KaggleDatasets().get_gcs_path('cassavafullrestfrecords')\n",
    "# # GCS_PATH_NEW = KaggleDatasets().get_gcs_path('cldc-ds-1121-size-512')\n",
    "# GCS_PATH_NEW = KaggleDatasets().get_gcs_path('cassavafullrestfrecords')\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = [600, 800]\n",
    "# IMAGE_SIZE = [512, 512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.int32)# / 255.0\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example, labeled=True):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = decode_image(example[\"image\"])\n",
    "    image_name = tf.cast(example[\"image_name\"], tf.string)\n",
    "    if labeled:\n",
    "        label = tf.cast(example[\"target\"], tf.int32)\n",
    "        return image, label, image_name\n",
    "    return image\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def input_preprocess(image, label, image_name):\n",
    "    image = tf.image.resize(image, size=IMAGE_SIZE)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=255)\n",
    "    image = tf.dtypes.cast(image, tf.int32)\n",
    "    # normalize according to imagenet mean and standard deviation\n",
    "#     image /= 255.0\n",
    "#     image = (image - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label, image_name\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_dataset(FILENAMES, BATCH_SIZE=12):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(input_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILENAMES = ['../MobileNet/full_res_TFRecords/Id_train18-1069.tfrec', \n",
    "                  '../MobileNet/full_res_TFRecords/Id_train19-1069.tfrec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "BATCH_SIZE = 36\n",
    "train_dataset = get_validation_dataset(TEST_FILENAMES, BATCH_SIZE=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label, filename in train_dataset.take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import sigmoid\n",
    "\n",
    "class SwishActivation(tf.keras.layers.Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(SwishActivation, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish_act'\n",
    "\n",
    "def swish_act(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "# from tf.keras.layers import Activation\n",
    "get_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n",
    "\n",
    "# from tensorflow.keras.experimental import CosineDecay\n",
    "import efficientnet.keras as eff\n",
    "\n",
    "# decay_steps = int(round(NUM_TRAINING_IMAGES/BATCH_SIZE))*EPOCHS\n",
    "# cosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "#     x = data_augmentation_layers(inputs)\n",
    "#     model = tf.keras.applications.EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "model = eff.EfficientNetB0(include_top=False, input_tensor=inputs, weights=None)\n",
    "\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "# model.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.2\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(1024, kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(swish_act)(x)\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(512, kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(swish_act)(x)\n",
    "x = tf.keras.layers.Dropout(top_dropout_rate)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
    "#     loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "#     model.compile(loss=taylor_cross_entropy_loss(), optimizer=tf.keras.optimizers.Adam(cosine_decay), \n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(cosine_decay), \n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('EfficientNet_B0_88243.h5')\n",
    "# model_pseudolabel = tf.keras.models.load_model('EfficientNetb0_pseudolabel_train.h5', \n",
    "#                                   custom_objects = {\"SwishActivation\": SwishActivation})\n",
    "\n",
    "# model = tf.keras.models.load_model('EfficientNetB0_512_512_87919.h5')\n",
    "# model_pseudolabel = tf.keras.models.load_model('EfficientNetb0_512x512_pseudolabel_train.h5', \n",
    "#                                   custom_objects = {\"SwishActivation\": SwishActivation})\n",
    "\n",
    "# model = tf.keras.models.load_model('EfficientNetB4_600_800_88739.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VALIDATION_IMAGES = count_data_items(TEST_FILENAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VALIDATION_IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds = []\n",
    "filenames = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for image, label, filename in train_dataset.take(NUM_VALIDATION_IMAGES//BATCH_SIZE + 1):\n",
    "    labels+=label.numpy().tolist()\n",
    "    pred = 0.5*model.predict(image)\n",
    "#     pred += 0.5*model_pseudolabel.predict(image)\n",
    "#     pred = model.predict(image)\n",
    "    preds+=pred.tolist()\n",
    "    filenames+=filename.numpy().tolist()\n",
    "    del image, label, filename\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=[np.argmax(y) for y in labels]\n",
    "y_pred=[np.argmax(y) for y in preds]\n",
    "acc = accuracy_score(y_label, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([np.max(y) for y in preds], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_label)):\n",
    "    if y_label[i] != y_pred[i]:\n",
    "        print('label: {0}, pred: {1}'.format(y_label[i], y_pred[i]))\n",
    "        print(i, filenames[i])\n",
    "        print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')\n",
    "df['image_id'] = '../input/train_images/' + df['image_id']\n",
    "df['label'] = df['label'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=90,\n",
    "                                                          width_shift_range=10,\n",
    "                                                          height_shift_range=10,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          vertical_flip=True,) \n",
    "#                                                          dtype = 'uint8')\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train_datagen_flow = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    target_size=(600, 800),\n",
    "    batch_size=32,\n",
    "    subset='training',)\n",
    "#     seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(train_datagen_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_datagen_flow.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = []\n",
    "i = 1\n",
    "for image, label in train_datagen_flow:\n",
    "    filenames+=train_datagen_flow.filenames[i*32:(i+1)*32]\n",
    "    print(filenames[0])\n",
    "    print(i*32)\n",
    "    i+=1\n",
    "    plt.imshow(tf.dtypes.cast(image[0], tf.int32))\n",
    "    plt.show()\n",
    "    if i>0:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filenames))\n",
    "print(len(set(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.dtypes.cast(image[0], tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.int32)# / 255.0\n",
    "    return image\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def input_preprocess(image, label, image_name):\n",
    "    image = tf.image.resize(image, size=IMAGE_SIZE)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=255)\n",
    "    image = tf.dtypes.cast(image, tf.int32)\n",
    "    # normalize according to imagenet mean and standard deviation\n",
    "#     image /= 255.0\n",
    "#     image = (image - IMAGENET_MEAN) / IMAGENET_STD\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label, image_name\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def read_tfrecord(example, labeled=True):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "#     image = decode_image(example[\"image\"])\n",
    "    image_name = tf.cast(example[\"image_name\"], tf.string)\n",
    "    if labeled:\n",
    "#         label = tf.cast(example[\"target\"], tf.int32)\n",
    "        return image_name\n",
    "#     return image\n",
    "\n",
    "def get_validation_dataset(FILENAMES, BATCH_SIZE=12):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "#     dataset = dataset.map(input_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# These files was the one the model was trained on\n",
    "\n",
    "FILES = glob.glob('../MobileNet/full_res_TFRecords/*tfrec')\n",
    "\n",
    "VALID = ['../MobileNet/full_res_TFRecords/Id_train11-1070.tfrec',\n",
    " '../MobileNet/full_res_TFRecords/Id_train05-1070.tfrec',\n",
    " '../MobileNet/full_res_TFRecords/Id_train02-1070.tfrec',\n",
    " '../MobileNet/full_res_TFRecords/Id_train01-1070.tfrec',\n",
    " '../MobileNet/full_res_TFRecords/Id_train13-1070.tfrec']\n",
    "\n",
    "TEST = ['../MobileNet/full_res_TFRecords/Id_train18-1070.tfrec',\n",
    "        '../MobileNet/full_res_TFRecords/Id_train19-1070.tfrec']\n",
    "\n",
    "FILES = [f for f in FILES if f not in VALID and f not in TEST]\n",
    "\n",
    "GET_FILENAMES = get_validation_dataset(FILES, BATCH_SIZE=120)\n",
    "\n",
    "train_files = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for filename in GET_FILENAMES.take(count_data_items(FILES)//120 + 1):\n",
    "    train_files+=(filename.numpy().tolist())\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(i)\n",
    "    i+=1\n",
    "    \n",
    "train_files = [t.decode() for t in train_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_preds_file = []\n",
    "\n",
    "model_pred = {}\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if np.max(preds[i]) > 0.65:\n",
    "        conf_preds_file.append(filenames[i].decode())\n",
    "        model_pred[filenames[i].decode()] = np.argmax(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conf_preds_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_id'] = '../input/train_images/' + df['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[ (df['image_id'].isin(conf_preds_file)) | (df['image_id'].isin(train_files)) ]\n",
    "df = df[ (df['image_id'].isin(conf_preds_file)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.apply(lambda row: model_pred[row['image_id']] if row['image_id'] \n",
    "                                   in model_pred.keys() else row['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('restest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "train_datagen_flow = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=None,\n",
    "    x_col='image_id',\n",
    "    y_col='label',\n",
    "    target_size=(800, 600),\n",
    "    batch_size=8,\n",
    "    subset='training',\n",
    "    seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_datagen_flow,\n",
    "          steps_per_epoch=1356//8,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
