{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from readTFRecords import *\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "# from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "IMAGE_SIZE = (512, 512)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "def read_tfrecord(example, labeled=True):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    # decode the TFRecord\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = decode_image(example[\"image\"])\n",
    "    \n",
    "    if labeled:\n",
    "        label = tf.cast(example[\"target\"], tf.int32)\n",
    "        image_name = tf.cast(example[\"image_name\"], tf.string)\n",
    "        return image, label, image_name\n",
    "    return image\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32)# / 255.0\n",
    "    return image\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_dataset(filenames, labeled=True):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        filenames\n",
    "    )  # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(\n",
    "        ignore_order\n",
    "    )  # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=True), num_parallel_calls=AUTOTUNE)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n",
    "    return dataset\n",
    "\n",
    "# One-hot / categorical encoding\n",
    "# Resize\n",
    "\n",
    "def input_preprocess(image, label,image_name):\n",
    "    image = tf.image.resize(image, size=IMAGE_SIZE)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=255)\n",
    "    image = tf.image.rgb_to_yuv(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label,image_name\n",
    "\n",
    "\n",
    "def get_training_dataset(FILENAMES, BATCH_SIZE=12):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)  \n",
    "    dataset = dataset.map(input_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "#     dataset = dataset.map(cutmix)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(FILENAMES, BATCH_SIZE=12):\n",
    "    dataset = load_dataset(FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(input_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_PATH = \"../input/train_tfrecords\"\n",
    "\n",
    "FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/*tfrec\")\n",
    "split_ind = int(0.9 * len(FILENAMES))\n",
    "# TRAINING_FILENAMES, VALID_FILENAMES = FILENAMES[:split_ind], FILENAMES[split_ind:]\n",
    "\n",
    "# TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(FILENAMES, test_size=0.2, random_state=420)\n",
    "\n",
    "# TRAINING_FILENAMES = ['gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train04-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train05-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train06-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train07-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train08-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train09-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train10-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train11-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train12-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train13-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train14-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train15-1327.tfrec']\n",
    "# VALID_FILENAMES = ['gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train00-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train01-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train02-1338.tfrec', 'gs://kds-3a224514a454fd9aa3d169e4b992b270639f50cb2562afc9a7f30028/train_tfrecords/ld_train03-1338.tfrec']\n",
    "\n",
    "TRAINING_FILENAMES = ['../input/train_tfrecords/ld_train04-1338.tfrec', '../input/train_tfrecords/ld_train05-1338.tfrec', '../input/train_tfrecords/ld_train06-1338.tfrec', '../input/train_tfrecords/ld_train07-1338.tfrec', '../input/train_tfrecords/ld_train08-1338.tfrec', '../input/train_tfrecords/ld_train09-1338.tfrec', '../input/train_tfrecords/ld_train10-1338.tfrec', '../input/train_tfrecords/ld_train11-1338.tfrec', '../input/train_tfrecords/ld_train12-1338.tfrec', '../input/train_tfrecords/ld_train13-1338.tfrec', '../input/train_tfrecords/ld_train14-1338.tfrec', '../input/train_tfrecords/ld_train15-1327.tfrec']\n",
    "VALID_FILENAMES = ['../input/train_tfrecords/ld_train00-1338.tfrec', '../input/train_tfrecords/ld_train01-1338.tfrec', '../input/train_tfrecords/ld_train02-1338.tfrec', '../input/train_tfrecords/ld_train03-1338.tfrec']\n",
    "\n",
    "TEST_FILENAMES = tf.io.gfile.glob(\"../input/test_tfrecords/*tfrec\")\n",
    "print(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\n",
    "print(\"Validation TFRecord Files:\", len(VALID_FILENAMES))\n",
    "print(\"Test TFRecord Files:\", len(TEST_FILENAMES))\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "\n",
    "print('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n",
    "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.experimental import CosineDecay\n",
    "import efficientnet.keras as eff\n",
    "\n",
    "decay_steps = int(round(NUM_TRAINING_IMAGES/BATCH_SIZE))*EPOCHS\n",
    "cosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n",
    "\n",
    "from keras.backend import sigmoid\n",
    "\n",
    "class SwishActivation(tf.keras.layers.Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(SwishActivation, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish_act'\n",
    "\n",
    "def swish_act(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "# from tf.keras.layers import Activation\n",
    "get_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "#     x = data_augmentation_layers(inputs)\n",
    "#     model = tf.keras.applications.EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "model = eff.EfficientNetB5(include_top=False, input_tensor=inputs, weights=None)\n",
    "\n",
    "\n",
    "# Freeze the pretrained weights\n",
    "# model.trainable = False\n",
    "\n",
    "# Rebuild top\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "top_dropout_rate = 0.1\n",
    "#     x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(512)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(swish_act)(x)\n",
    "#     x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(256)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation(swish_act)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "# Compile\n",
    "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.4)\n",
    "#     loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(cosine_decay), \n",
    "          metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/usmanr/Downloads/EfficientNetB5_yuv_smooting.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_validation_dataset(VALID_FILENAMES, BATCH_SIZE=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label, filename in train_dataset.take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(image[0:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0,:,:,0]/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(4279//20):\n",
    "labels = []\n",
    "preds = []\n",
    "filenames = []\n",
    "\n",
    "i = 1\n",
    "for image, label, filename in train_dataset.take(45):\n",
    "    labels+=label.numpy().tolist()\n",
    "    pred = model.predict(image)\n",
    "    preds+=pred.tolist()\n",
    "    filenames+=filename.numpy().tolist()\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filenames))\n",
    "print(len(set(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label=[np.argmax(y) for y in labels]\n",
    "y_pred=[np.argmax(y) for y in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaking_point = 0\n",
    "mixed_precision = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if np.max(preds[i]) < 0.6:\n",
    "        print(filenames[i])\n",
    "        mixed_precision.append(filenames[i])\n",
    "        \n",
    "        breaking_point+=1\n",
    "#     if breaking_point > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[0].decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../input/train_images/' + mixed_precision[1].decode(\"utf-8\") )\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mixed_precision)):\n",
    "    print(mixed_precision[i].decode(\"utf-8\")  + ',', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
